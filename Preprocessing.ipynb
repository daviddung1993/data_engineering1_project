{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f9cf3b",
   "metadata": {},
   "source": [
    "# Project Group 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb3c30",
   "metadata": {},
   "source": [
    "### Preprocessing, to deal with Null values and to unify dataframes, one for uber data and one for For-Hire Vehicle data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48834a48",
   "metadata": {},
   "source": [
    "### Setting up a Spark Session to work with structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f36790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1969b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the code on local machine or on server\n",
    "server_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34bce2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:43:39 WARN Utils: Your hostname, nanook resolves to a loopback address: 127.0.1.1; using 192.168.0.197 instead (on interface wlp9s0)\n",
      "22/03/18 12:43:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/naeim/anaconda3/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/18 12:43:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/18 12:43:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/03/18 12:43:41 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "if server_mode:\n",
    "    #New API\n",
    "    spark_session = SparkSession\\\n",
    "            .builder\\\n",
    "            .master(\"spark://192.168.2.74:7077\") \\\n",
    "            .appName(\"Project_G1_Naeim\")\\\n",
    "            .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "            .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "            .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "            .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"300s\")\\\n",
    "            .config(\"spark.cores.max\",5)\\\n",
    "            .config(\"spark.cores.min\",5)\\\n",
    "            .config(\"spark.driver.port\",9998)\\\n",
    "            .config(\"spark.blockManager.port\",10005)\\\n",
    "            .getOrCreate()\n",
    "\n",
    "    # Old API (RDD)\n",
    "    spark_context = spark_session.sparkContext\n",
    "    spark_context.setLogLevel(\"ERROR\")\n",
    "    # spark_context.setLogLevel(\"INFO\")\n",
    "    \n",
    "else:\n",
    "    # local version, deactivate later!\n",
    "    spark_session = SparkSession.builder.appName('Project_G1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07711204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.197:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Project_G1</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd19465ed90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_session # to get some info about the Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145c744",
   "metadata": {},
   "source": [
    "### Check the existing source files and their names in the remote directories before downloading them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563f4dec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files with csv extension: 19\n",
      "['taxi-zone-lookup.csv', 'uber-raw-data-apr14.csv', 'uber-raw-data-aug14.csv', 'uber-raw-data-jul14.csv', 'uber-raw-data-jun14.csv']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "\n",
    "urls = ['https://github.com/fivethirtyeight/uber-tlc-foil-response/blob/master/uber-trip-data/',\n",
    "        'https://github.com/fivethirtyeight/uber-tlc-foil-response/blob/master/other-FHV-data/',\n",
    "        'https://github.com/fivethirtyeight/uber-tlc-foil-response/']\n",
    "\n",
    "exts = ['csv'] #, 'xlsx'\n",
    "\n",
    "def get_content(url, ext=''):\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    return [url + '/' + node.get('href') for node in soup.find_all('a') if node.get('href').endswith(ext)]\n",
    "file_names = []\n",
    "\n",
    "for url in urls:\n",
    "    for ext in exts:\n",
    "        for file in get_content(url, ext):\n",
    "            file_names.append(os.path.basename(file))\n",
    "\n",
    "print(f'Number of files with csv extension: {len(file_names)}')\n",
    "print(file_names[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07153807",
   "metadata": {},
   "source": [
    "### Download source files in local file system before working with Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3449c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The repository is ALREADY downloaded!\n"
     ]
    }
   ],
   "source": [
    "# !pip install gitpython\n",
    "from git import Repo\n",
    "if not os.path.isdir('DATA') or len(os.listdir('DATA')) == 0:\n",
    "    git_url = 'https://github.com/fivethirtyeight/uber-tlc-foil-response.git'\n",
    "    Repo.clone_from(git_url, 'Git_repo');\n",
    "    print('The repository is downloaded!')\n",
    "else:\n",
    "    print('The repository is ALREADY downloaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbf18dc",
   "metadata": {},
   "source": [
    "### Keeping useful files from git repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d38724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['csv'] files already extracted!\n",
      "Number of new ['csv'] extracted files: 19\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "src = r'Git_repo'\n",
    "if os.path.isdir('Git_repo'):\n",
    "    os.system(\"rm -rf DATA\")\n",
    "    os.makedirs('DATA')\n",
    "    print(\"Old DATA directory deleted!\")\n",
    "    dest = r'DATA'\n",
    "\n",
    "    for path, subdirs, files in os.walk(src):\n",
    "        if '.git' in subdirs:\n",
    "            subdirs.remove('.git')\n",
    "        for name in files:\n",
    "            if name.endswith('.csv'): # or name.endswith('.xlsx'):\n",
    "                filename = os.path.join(path, name)\n",
    "                shutil.copy2(filename, dest)\n",
    "else:\n",
    "    print(f\"{exts} files already extracted!\")\n",
    "\n",
    "if os.path.isdir('DATA'):\n",
    "    path = os.getcwd() + '/DATA'\n",
    "    list_dir = os.listdir(path)\n",
    "    count = 0\n",
    "    for file in list_dir:\n",
    "        if file.endswith(exts[0]):\n",
    "            count += 1\n",
    "    print(f\"Number of new {exts} extracted files: {count}\")\n",
    "os.system(\"rm -rf Git_repo\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e380e56f",
   "metadata": {},
   "source": [
    "### Load the CSV files from source folder, and call show() to verify the data is loaded to RAM correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1b3c08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Laodig data in Spark & writing in HDFS\n",
    "df_list = {}\n",
    "for file in file_names:\n",
    "    # spark_file = 'df_'+ (os.path.splitext(file)[0]).split('-')[-1]\n",
    "    # df_list[file] = spark_session.read.csv('DATA/'+file, header=True, inferSchema=True)\n",
    "    df_list[file] = spark_session.read.option(\"header\",\"true\").csv('DATA/'+file)\n",
    "\n",
    "# df_list.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9c8b251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark dataframe exists\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql\n",
    "if df_list[file_names[0]] is not None and \\\n",
    "                isinstance(df_list[file_names[0]], \\\n",
    "                    pyspark.sql.dataframe.DataFrame):\n",
    "    print(\"Spark dataframe exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08e03dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('taxi-zone-lookup.csv', pyspark.sql.dataframe.DataFrame)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names[0], type(df_list[file_names[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ede443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------+\n",
      "|LocationID|Borough|          Zone|\n",
      "+----------+-------+--------------+\n",
      "|         1|    EWR|Newark Airport|\n",
      "|         2| Queens|   Jamaica Bay|\n",
      "+----------+-------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_list[file_names[0]].show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ff380a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_list[file_names[0]].printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8321d34",
   "metadata": {},
   "source": [
    "### Check missing or Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a694e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code is inspired by 'pault' @ stackoverflow\n",
    "# Pyspark - Calculate number of null values in each dataframe column\n",
    "\n",
    "import pyspark.sql.functions as func\n",
    "from functools import reduce\n",
    "\n",
    "def count_null_values_in_df(any_df):\n",
    "    \n",
    "    df_agg = any_df.agg(*[func.count(func.when(func.isnull(c), c)).alias(c) for c in any_df.columns])\n",
    "    null_table = reduce(lambda a, b: a.union(b),(\n",
    "        df_agg.select(func.lit(c).alias(\"Column\"), func.col(c).alias(\"Nbr of Null\")) \n",
    "        for c in df_agg.columns))\n",
    "    \n",
    "    null_table.show()\n",
    "    print(f'Initial number of rows: {any_df.count()}')\n",
    "    print(\"************\\n\")\n",
    "    \n",
    "    any_df = any_df.na.drop(how='all') # to drop any row with all values as Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7ffaa8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: uber-raw-data-apr14.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|   Column|Nbr of Null|\n",
      "+---------+-----------+\n",
      "|Date/Time|          0|\n",
      "|      Lat|          0|\n",
      "|      Lon|          0|\n",
      "|     Base|          0|\n",
      "+---------+-----------+\n",
      "\n",
      "Initial number of rows: 564516\n",
      "************\n",
      "\n",
      "2: uber-raw-data-aug14.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|   Column|Nbr of Null|\n",
      "+---------+-----------+\n",
      "|Date/Time|          0|\n",
      "|      Lat|          0|\n",
      "|      Lon|          0|\n",
      "|     Base|          0|\n",
      "+---------+-----------+\n",
      "\n",
      "Initial number of rows: 829275\n",
      "************\n",
      "\n",
      "3: uber-raw-data-jul14.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|   Column|Nbr of Null|\n",
      "+---------+-----------+\n",
      "|Date/Time|          0|\n",
      "|      Lat|          0|\n",
      "|      Lon|          0|\n",
      "|     Base|          0|\n",
      "+---------+-----------+\n",
      "\n",
      "Initial number of rows: 796121\n",
      "************\n",
      "\n",
      "4: uber-raw-data-jun14.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|   Column|Nbr of Null|\n",
      "+---------+-----------+\n",
      "|Date/Time|          0|\n",
      "|      Lat|          0|\n",
      "|      Lon|          0|\n",
      "|     Base|          0|\n",
      "+---------+-----------+\n",
      "\n",
      "Initial number of rows: 663844\n",
      "************\n",
      "\n",
      "5: uber-raw-data-may14.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|   Column|Nbr of Null|\n",
      "+---------+-----------+\n",
      "|Date/Time|          0|\n",
      "|      Lat|          0|\n",
      "|      Lon|          0|\n",
      "|     Base|          0|\n",
      "+---------+-----------+\n",
      "\n",
      "Initial number of rows: 652435\n",
      "************\n",
      "\n",
      "6: uber-raw-data-sep14.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|   Column|Nbr of Null|\n",
      "+---------+-----------+\n",
      "|Date/Time|          0|\n",
      "|      Lat|          0|\n",
      "|      Lon|          0|\n",
      "|     Base|          0|\n",
      "+---------+-----------+\n",
      "\n",
      "Initial number of rows: 1028136\n",
      "************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "for key in df_list.keys():\n",
    "    if 'uber-raw-data' in key:\n",
    "        print(f'{x}: {key}')\n",
    "        count_null_values_in_df(df_list[key])   \n",
    "        x += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeab903",
   "metadata": {},
   "source": [
    "### Preparing Uber raw data\n",
    "Uber data (4.5 million Uber pickups in New York City from April to September 2014, and 14.3 million more Uber pickups from January to June 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eb5239a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date/Time', 'Lat', 'Lon', 'Base']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = df_list['uber-raw-data-apr14.csv'].schema.names\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "402553b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 92:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+---+----+\n",
      "|Date/Time|Lat|Lon|Base|\n",
      "+---------+---+---+----+\n",
      "+---------+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "sc = spark_session.sparkContext\n",
    "\n",
    "col_names = df_list['uber-raw-data-apr14.csv'].schema.names\n",
    "mySchema = StructType([StructField(c, StringType()) for c in col_names])\n",
    "uber_raw_data = SparkSession(sc).createDataFrame(data=[], schema=mySchema)\n",
    "uber_raw_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31056fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files combined: 6\n",
      "Total number of rows in unified dataframe: 4534327\n"
     ]
    }
   ],
   "source": [
    "manual_rows = 0\n",
    "number_of_files = 0\n",
    "for key in df_list.keys():\n",
    "    if 'uber-raw-data' in key:\n",
    "        uber_raw_data = uber_raw_data.union(df_list[key])\n",
    "        manual_rows += df_list[key].count()\n",
    "        number_of_files += 1\n",
    "\n",
    "print(f\"Total number of files combined: {number_of_files}\")\n",
    "print(f'Total number of rows in unified dataframe: {manual_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f933cf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 112:===============================================>       (24 + 4) / 28]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows match in the unified file!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if (uber_raw_data.count() == manual_rows):\n",
    "    print(\"The number of rows match in the unified file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb389091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if server_mode:\n",
    "    path = 'hdfs://192.168.2.74:9000/user/ubuntu/uber-tlc-foil-response/uber-trip-data'\n",
    "else:\n",
    "    path = os.getcwd() + '/DATA/'\n",
    "\n",
    "uber_unified_file = path+\"uber_raw_data.parquet\"\n",
    "uber_raw_data.write.mode(\"overwrite\").parquet(uber_unified_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6306d5",
   "metadata": {},
   "source": [
    "### To check if downloaded files exist in DFS system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "942573a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "fs = sc._jvm.org.apache.hadoop.fs.FileSystem.get(sc._jsc.hadoopConfiguration())\n",
    "if server_mode:\n",
    "    path = 'hdfs://192.168.2.74:9000/user/ubuntu/uber-tlc-foil-response/uber-trip-data/'\n",
    "else:\n",
    "    path = os.getcwd() + '/DATA/'\n",
    "\n",
    "path = path + 'uber_raw_data.parquet'\n",
    "print(fs.exists(sc._jvm.org.apache.hadoop.fs.Path(path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798757e9",
   "metadata": {},
   "source": [
    "## Read the unified \"uber_raw_data\" file in parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56d53678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date/Time: string (nullable = true)\n",
      " |-- Lat: string (nullable = true)\n",
      " |-- Lon: string (nullable = true)\n",
      " |-- Base: string (nullable = true)\n",
      "\n",
      "+----------------+-------+--------+------+\n",
      "|       Date/Time|    Lat|     Lon|  Base|\n",
      "+----------------+-------+--------+------+\n",
      "|9/1/2014 0:01:00|40.2201|-74.0021|B02512|\n",
      "|9/1/2014 0:01:00|  40.75|-74.0027|B02512|\n",
      "|9/1/2014 0:03:00|40.7559|-73.9864|B02512|\n",
      "+----------------+-------+--------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4534327"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_raw_data_read_test = spark_session.read.parquet(uber_unified_file)\n",
    "uber_raw_data_read_test.printSchema()\n",
    "uber_raw_data_read_test.show(3)\n",
    "uber_raw_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fae0a9e",
   "metadata": {},
   "source": [
    "### Preparing For-Hire Vehicle (FHV) data\n",
    "FHV companies (10 files of raw data on pickups from 10 FHV companies. The trip information varies by company, but can include day of trip, time of trip, pickup location, driver's for-hire license number, and vehicle's for-hire license number.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e080354",
   "metadata": {},
   "source": [
    "#### Drop Null columns manually for each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c02e73f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: taxi-zone-lookup.csv\n",
      "[('LocationID', 'string'), ('Borough', 'string'), ('Zone', 'string')]\n",
      "+----------+-----------+\n",
      "|    Column|Nbr of Null|\n",
      "+----------+-----------+\n",
      "|LocationID|          0|\n",
      "|   Borough|          0|\n",
      "|      Zone|          0|\n",
      "+----------+-----------+\n",
      "\n",
      "Initial number of rows: 265\n",
      "************\n",
      "\n",
      "2: American_B01362.csv\n",
      "[('DATE', 'string'), ('TIME', 'string'), ('PICK UP ADDRESS', 'string'), ('_c3', 'string'), ('_c4', 'string'), ('_c5', 'string')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:44:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c3\n",
      "Expected: _c3 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/American_B01362.csv\n",
      "22/03/18 12:44:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c4\n",
      "Expected: _c4 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/American_B01362.csv\n",
      "22/03/18 12:44:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c5\n",
      "Expected: _c5 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/American_B01362.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+\n",
      "|         Column|Nbr of Null|\n",
      "+---------------+-----------+\n",
      "|           DATE|          0|\n",
      "|           TIME|          0|\n",
      "|PICK UP ADDRESS|          0|\n",
      "|            _c3|      91712|\n",
      "|            _c4|      91712|\n",
      "|            _c5|      91712|\n",
      "+---------------+-----------+\n",
      "\n",
      "Initial number of rows: 91712\n",
      "************\n",
      "\n",
      "3: Carmel_B00256.csv\n",
      "[('Date', 'string'), ('Time', 'string'), ('PU_Adress', 'string'), ('Base_No', 'string')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|   Column|Nbr of Null|\n",
      "+---------+-----------+\n",
      "|     Date|          0|\n",
      "|     Time|          0|\n",
      "|PU_Adress|          0|\n",
      "|  Base_No|          0|\n",
      "+---------+-----------+\n",
      "\n",
      "Initial number of rows: 256519\n",
      "************\n",
      "\n",
      "4: Dial7_B00887.csv\n",
      "[('Date', 'string'), ('Time', 'string'), ('State', 'string'), ('PuFrom', 'string'), ('Address', 'string'), ('Street', 'string')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "| Column|Nbr of Null|\n",
      "+-------+-----------+\n",
      "|   Date|          0|\n",
      "|   Time|          0|\n",
      "|  State|          0|\n",
      "| PuFrom|      37030|\n",
      "|Address|          0|\n",
      "| Street|          0|\n",
      "+-------+-----------+\n",
      "\n",
      "Initial number of rows: 194992\n",
      "************\n",
      "\n",
      "5: Diplo_B01196.csv\n",
      "[('Date', 'string'), ('Time', 'string'), ('PU_Address', 'string')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|    Column|Nbr of Null|\n",
      "+----------+-----------+\n",
      "|      Date|          0|\n",
      "|      Time|          0|\n",
      "|PU_Address|          0|\n",
      "+----------+-----------+\n",
      "\n",
      "Initial number of rows: 98550\n",
      "************\n",
      "\n",
      "6: Federal_02216.csv\n",
      "[('Date', 'string'), ('Time', 'string'), ('PU_Address2', 'string'), ('DO_Address', 'string'), ('Routing Details', 'string'), ('PU_Address5', 'string'), ('Status', 'string')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:45:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PU_Address\n",
      " Schema: PU_Address2\n",
      "Expected: PU_Address2 but found: PU_Address\n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/Federal_02216.csv\n",
      "22/03/18 12:45:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: PU_Address\n",
      " Schema: PU_Address5\n",
      "Expected: PU_Address5 but found: PU_Address\n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/Federal_02216.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+\n",
      "|         Column|Nbr of Null|\n",
      "+---------------+-----------+\n",
      "|           Date|          0|\n",
      "|           Time|          0|\n",
      "|    PU_Address2|          7|\n",
      "|     DO_Address|          9|\n",
      "|Routing Details|          0|\n",
      "|    PU_Address5|          0|\n",
      "|         Status|          0|\n",
      "+---------------+-----------+\n",
      "\n",
      "Initial number of rows: 276\n",
      "************\n",
      "\n",
      "7: Firstclass_B01536.csv\n",
      "[('DATE', 'string'), ('TIME', 'string'), ('PICK UP ADDRESS', 'string')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+\n",
      "|         Column|Nbr of Null|\n",
      "+---------------+-----------+\n",
      "|           DATE|          0|\n",
      "|           TIME|          0|\n",
      "|PICK UP ADDRESS|          0|\n",
      "+---------------+-----------+\n",
      "\n",
      "Initial number of rows: 166769\n",
      "************\n",
      "\n",
      "8: Highclass_B01717.csv\n",
      "[('DATE', 'string'), ('TIME', 'string'), ('PU_Address', 'string')]\n",
      "+----------+-----------+\n",
      "|    Column|Nbr of Null|\n",
      "+----------+-----------+\n",
      "|      DATE|          0|\n",
      "|      TIME|          0|\n",
      "|PU_Address|          0|\n",
      "+----------+-----------+\n",
      "\n",
      "Initial number of rows: 151925\n",
      "************\n",
      "\n",
      "9: Lyft_B02510.csv\n",
      "[('time_of_trip', 'string'), ('start_lat', 'string'), ('start_lng', 'string'), ('_c3', 'string')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:45:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c3\n",
      "Expected: _c3 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/Lyft_B02510.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|      Column|Nbr of Null|\n",
      "+------------+-----------+\n",
      "|time_of_trip|          0|\n",
      "|   start_lat|          1|\n",
      "|   start_lng|          1|\n",
      "|         _c3|     266503|\n",
      "+------------+-----------+\n",
      "\n",
      "Initial number of rows: 267701\n",
      "************\n",
      "\n",
      "10: Prestige_B01338.csv\n",
      "[('DATE', 'string'), ('TIME', 'string'), ('PICK UP ADDRESS', 'string')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+\n",
      "|         Column|Nbr of Null|\n",
      "+---------------+-----------+\n",
      "|           DATE|          0|\n",
      "|           TIME|          0|\n",
      "|PICK UP ADDRESS|          0|\n",
      "+---------------+-----------+\n",
      "\n",
      "Initial number of rows: 320641\n",
      "************\n",
      "\n",
      "11: Skyline_B00111.csv\n",
      "[('Date', 'string'), ('Time', 'string'), ('    Street_Address ', 'string'), ('    City_State ', 'string'), ('_c4', 'string'), ('_c5', 'string')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:45:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c4\n",
      "Expected: _c4 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/Skyline_B00111.csv\n",
      "22/03/18 12:45:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c5\n",
      "Expected: _c5 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/Skyline_B00111.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+\n",
      "|             Column|Nbr of Null|\n",
      "+-------------------+-----------+\n",
      "|               Date|          0|\n",
      "|               Time|          0|\n",
      "|    Street_Address |          0|\n",
      "|        City_State |          0|\n",
      "|                _c4|     127696|\n",
      "|                _c5|     127696|\n",
      "+-------------------+-----------+\n",
      "\n",
      "Initial number of rows: 127696\n",
      "************\n",
      "\n",
      "12: other-FHV-data-jan-aug-2015.csv\n",
      "[('_c0', 'string'), ('_c1', 'string'), ('_c2', 'string'), ('_c3', 'string'), ('_c4', 'string'), ('_c5', 'string'), ('_c6', 'string')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:45:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c0\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/other-FHV-data-jan-aug-2015.csv\n",
      "22/03/18 12:45:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c1\n",
      "Expected: _c1 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/other-FHV-data-jan-aug-2015.csv\n",
      "22/03/18 12:45:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c2\n",
      "Expected: _c2 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/other-FHV-data-jan-aug-2015.csv\n",
      "22/03/18 12:45:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c3\n",
      "Expected: _c3 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/other-FHV-data-jan-aug-2015.csv\n",
      "22/03/18 12:45:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c4\n",
      "Expected: _c4 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/other-FHV-data-jan-aug-2015.csv\n",
      "22/03/18 12:45:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c5\n",
      "Expected: _c5 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/other-FHV-data-jan-aug-2015.csv\n",
      "22/03/18 12:45:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c6\n",
      "Expected: _c6 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/other-FHV-data-jan-aug-2015.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+\n",
      "|Column|Nbr of Null|\n",
      "+------+-----------+\n",
      "|   _c0|      26186|\n",
      "|   _c1|          5|\n",
      "|   _c2|          5|\n",
      "|   _c3|      26187|\n",
      "|   _c4|          5|\n",
      "|   _c5|          5|\n",
      "|   _c6|          5|\n",
      "+------+-----------+\n",
      "\n",
      "Initial number of rows: 26187\n",
      "************\n",
      "\n",
      "13: Uber-Jan-Feb-FOIL.csv\n",
      "[('dispatching_base_number', 'string'), ('date', 'string'), ('active_vehicles', 'string'), ('trips', 'string')]\n",
      "+--------------------+-----------+\n",
      "|              Column|Nbr of Null|\n",
      "+--------------------+-----------+\n",
      "|dispatching_base_...|          0|\n",
      "|                date|          0|\n",
      "|     active_vehicles|          0|\n",
      "|               trips|          0|\n",
      "+--------------------+-----------+\n",
      "\n",
      "Initial number of rows: 354\n",
      "************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "for key in df_list.keys():\n",
    "    if 'uber-raw-data' not in key:\n",
    "        print(f'{x}: {key}')\n",
    "        print(df_list[key].dtypes)\n",
    "        count_null_values_in_df(df_list[key]) \n",
    "        x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c60971a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|   PuFrom|\n",
      "+---------+\n",
      "|MANHATTAN|\n",
      "|MANHATTAN|\n",
      "|MANHATTAN|\n",
      "|MANHATTAN|\n",
      "|MANHATTAN|\n",
      "|MANHATTAN|\n",
      "|MANHATTAN|\n",
      "|MANHATTAN|\n",
      "|   QUEENS|\n",
      "|MANHATTAN|\n",
      "+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list['Dial7_B00887.csv'].select('PuFrom').show(10)\n",
    "df_list['Dial7_B00887.csv'] = df_list['Dial7_B00887.csv']\\\n",
    "                        .na.fill('UNKOWN')\n",
    "df_list['Dial7_B00887.csv'].filter(df_list['Dial7_B00887.csv']\\\n",
    "                        .PuFrom.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "912a2b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+----+----+----+\n",
      "|    DATE|       TIME|     PICK UP ADDRESS| _c3| _c4| _c5|\n",
      "+--------+-----------+--------------------+----+----+----+\n",
      "|7/1/2014|12:00:00 AM| 874 E 139th St M...|null|null|null|\n",
      "|7/1/2014|12:01:00 AM| 628 E 141st St M...|null|null|null|\n",
      "|7/1/2014|12:01:00 AM| 601 E 156th St S...|null|null|null|\n",
      "|7/1/2014|12:01:00 AM| 708 E 138th St M...|null|null|null|\n",
      "|7/1/2014|12:02:00 AM| 700 E 140th St M...|null|null|null|\n",
      "+--------+-----------+--------------------+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+-----------+--------------------+\n",
      "|    DATE|       TIME|     PICK UP ADDRESS|\n",
      "+--------+-----------+--------------------+\n",
      "|7/1/2014|12:00:00 AM| 874 E 139th St M...|\n",
      "|7/1/2014|12:01:00 AM| 628 E 141st St M...|\n",
      "+--------+-----------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:45:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: DATE, TIME, PICK UP ADDRESS, , , \n",
      " Schema: DATE, TIME, PICK UP ADDRESS, _c3, _c4, _c5\n",
      "Expected: _c3 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/American_B01362.csv\n"
     ]
    }
   ],
   "source": [
    "df_list['American_B01362.csv'].show(5)\n",
    "columns_to_drop = ['_c3','_c4','_c5']\n",
    "df_list['American_B01362.csv'] = \\\n",
    "    df_list['American_B01362.csv'].drop(*columns_to_drop)\n",
    "df_list['American_B01362.csv'].show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "672d18d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:45:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: time_of_trip, start_lat, start_lng, \n",
      " Schema: time_of_trip, start_lat, start_lng, _c3\n",
      "Expected: _c3 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/Lyft_B02510.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+---------+----+\n",
      "|   time_of_trip|start_lat|start_lng| _c3|\n",
      "+---------------+---------+---------+----+\n",
      "|  9/4/2014 9:51| 40.64705|-73.77988|null|\n",
      "|8/27/2014 21:13| 40.74916|-73.98373|null|\n",
      "+---------------+---------+---------+----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---------------+---------+---------+\n",
      "|   time_of_trip|start_lat|start_lng|\n",
      "+---------------+---------+---------+\n",
      "|  9/4/2014 9:51| 40.64705|-73.77988|\n",
      "|8/27/2014 21:13| 40.74916|-73.98373|\n",
      "+---------------+---------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_list['Lyft_B02510.csv'].show(2)\n",
    "df_list['Lyft_B02510.csv'] = \\\n",
    "    df_list['Lyft_B02510.csv'].drop('_c3')\n",
    "df_list['Lyft_B02510.csv'].show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e799102b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:45:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Date, Time,     Street_Address ,     City_State , , \n",
      " Schema: Date, Time,     Street_Address ,     City_State , _c4, _c5\n",
      "Expected: _c4 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/Skyline_B00111.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+--------------------+--------------------+----+----+\n",
      "|    Date|          Time|     Street_Address |         City_State | _c4| _c5|\n",
      "+--------+--------------+--------------------+--------------------+----+----+\n",
      "|7/1/2014|    20:27     |    622 THIRD AV ...|     M           ...|null|null|\n",
      "|7/1/2014|    21:04     |     E 77TH ST   ...|     M           ...|null|null|\n",
      "+--------+--------------+--------------------+--------------------+----+----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------+--------------+--------------------+--------------------+\n",
      "|    Date|          Time|     Street_Address |         City_State |\n",
      "+--------+--------------+--------------------+--------------------+\n",
      "|7/1/2014|    20:27     |    622 THIRD AV ...|     M           ...|\n",
      "|7/1/2014|    21:04     |     E 77TH ST   ...|     M           ...|\n",
      "+--------+--------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_list['Skyline_B00111.csv'].show(2)\n",
    "df_list['Skyline_B00111.csv'] = \\\n",
    "    df_list['Skyline_B00111.csv'].drop(*columns_to_drop)\n",
    "df_list['Skyline_B00111.csv'].show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c54e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['_c0','_c3']\n",
    "df_list['other-FHV-data-jan-aug-2015.csv'] = \\\n",
    "    df_list['other-FHV-data-jan-aug-2015.csv'].drop(*columns_to_drop)\n",
    "df_list['other-FHV-data-jan-aug-2015.csv'] = \\\n",
    "    df_list['other-FHV-data-jan-aug-2015.csv'].na.drop(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40195b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------------+---------------+------------------+\n",
      "|        _c1|      _c2|         _c4|            _c5|               _c6|\n",
      "+-----------+---------+------------+---------------+------------------+\n",
      "|Base Number|Base Name|Pick Up Date|Number of Trips|Number of Vehicles|\n",
      "+-----------+---------+------------+---------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:45:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , , , , \n",
      " Schema: _c1, _c2, _c4, _c5, _c6\n",
      "Expected: _c1 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/other-FHV-data-jan-aug-2015.csv\n"
     ]
    }
   ],
   "source": [
    "df_list['other-FHV-data-jan-aug-2015.csv'].show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c254ed23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:45:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , , , , \n",
      " Schema: _c1, _c2, _c4, _c5, _c6\n",
      "Expected: _c1 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/other-FHV-data-jan-aug-2015.csv\n",
      "22/03/18 12:45:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , , , , \n",
      " Schema: _c1, _c2, _c4, _c5, _c6\n",
      "Expected: _c1 but found: \n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/other-FHV-data-jan-aug-2015.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------+---------------+------------------+\n",
      "|Base_Number|           Base_Name|Pick_Up_Date|Number_of_Trips|Number_of_Vehicles|\n",
      "+-----------+--------------------+------------+---------------+------------------+\n",
      "|     B00013|   LOVE CORP CAR INC|  01/01/2015|            26 |               17 |\n",
      "|     B00014| NY ONE CORP CAR INC|  01/01/2015|            45 |               24 |\n",
      "|     B00029|COMMUNITY CAR SVC...|  01/01/2015|           731 |               36 |\n",
      "|     B00053| CHARGE AND RIDE INC|  01/01/2015|            10 |                9 |\n",
      "|     B00095|LIBERTY CAR SERVI...|  01/01/2015|           814 |               62 |\n",
      "|     B00221|PROFESSIONAL CAR ...|  01/01/2015|           220 |               46 |\n",
      "|     B00227|PARK WEST EXEC. S...|  01/01/2015|            36 |               28 |\n",
      "|     B00248|YELLOWSTONE TRANS...|  01/01/2015|         1,137 |              106 |\n",
      "|     B00254|   XYZ TWO WAY RADIO|  01/01/2015|           236 |              103 |\n",
      "|     B00280|FLEET RADIO DISPA...|  01/01/2015|            47 |               29 |\n",
      "+-----------+--------------------+------------+---------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_list['other-FHV-data-jan-aug-2015.csv'] = \\\n",
    "        df_list['other-FHV-data-jan-aug-2015.csv'].withColumnRenamed(\"_c1\", \"Base_Number\")\\\n",
    "       .withColumnRenamed(\"_c2\", \"Base_Name\").withColumnRenamed(\"_c4\", \"Pick_Up_Date\")\\\n",
    "       .withColumnRenamed(\"_c5\", \"Number_of_Trips\").withColumnRenamed(\"_c6\", \"Number_of_Vehicles\")\n",
    "\n",
    "df_list['other-FHV-data-jan-aug-2015.csv'] = \\\n",
    "        SparkSession(sc).createDataFrame(df_list['other-FHV-data-jan-aug-2015.csv']\\\n",
    "                              .tail(df_list['other-FHV-data-jan-aug-2015.csv'].count()-1)\\\n",
    "                              ,df_list['other-FHV-data-jan-aug-2015.csv'].schema)\n",
    "\n",
    "df_list['other-FHV-data-jan-aug-2015.csv'].show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d839c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list['Lyft_B02510.csv'] = df_list['Lyft_B02510.csv'].na.drop()\n",
    "df_list['Federal_02216.csv'] = df_list['Federal_02216.csv']\\\n",
    "                        .na.fill('UNKOWN')\n",
    "\n",
    "df_list['American_B01362.csv'] = \\\n",
    "        df_list['American_B01362.csv'].withColumnRenamed(\"PICK UP ADDRESS\", \"PICK_UP_ADDRESS\")\n",
    "df_list['Prestige_B01338.csv'] = \\\n",
    "        df_list['Prestige_B01338.csv'].withColumnRenamed(\"PICK UP ADDRESS\", \"PICK_UP_ADDRESS\")\n",
    "\n",
    "df_list['Firstclass_B01536.csv'] = \\\n",
    "        df_list['Firstclass_B01536.csv'].withColumnRenamed(\"PICK UP ADDRESS\", \"PICK_UP_ADDRESS\")\n",
    "df_list['Federal_02216.csv'] = \\\n",
    "        df_list['Federal_02216.csv'].withColumnRenamed(\"Routing Details\", \"Routing_Details\")\n",
    "\n",
    "df_list['Skyline_B00111.csv'] = \\\n",
    "        df_list['Skyline_B00111.csv'].withColumnRenamed(\"    Street_Address \", \"Street_Address\")\n",
    "df_list['Skyline_B00111.csv'] = \\\n",
    "        df_list['Skyline_B00111.csv'].withColumnRenamed(\"    City_State \", \"City_State\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89d838d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: taxi-zone-lookup.csv\n",
      "[('LocationID', 'string'), ('Borough', 'string'), ('Zone', 'string')]\n",
      "+----------+-------+--------------------+\n",
      "|LocationID|Borough|                Zone|\n",
      "+----------+-------+--------------------+\n",
      "|         1|    EWR|      Newark Airport|\n",
      "|         2| Queens|         Jamaica Bay|\n",
      "|         3|  Bronx|Allerton/Pelham G...|\n",
      "+----------+-------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+----------+-----------+\n",
      "|    Column|Nbr of Null|\n",
      "+----------+-----------+\n",
      "|LocationID|          0|\n",
      "|   Borough|          0|\n",
      "|      Zone|          0|\n",
      "+----------+-----------+\n",
      "\n",
      "Initial number of rows: 265\n",
      "************\n",
      "\n",
      "2: American_B01362.csv\n",
      "[('DATE', 'string'), ('TIME', 'string'), ('PICK_UP_ADDRESS', 'string')]\n",
      "+--------+-----------+--------------------+\n",
      "|    DATE|       TIME|     PICK_UP_ADDRESS|\n",
      "+--------+-----------+--------------------+\n",
      "|7/1/2014|12:00:00 AM| 874 E 139th St M...|\n",
      "|7/1/2014|12:01:00 AM| 628 E 141st St M...|\n",
      "|7/1/2014|12:01:00 AM| 601 E 156th St S...|\n",
      "+--------+-----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+---------------+-----------+\n",
      "|         Column|Nbr of Null|\n",
      "+---------------+-----------+\n",
      "|           DATE|          0|\n",
      "|           TIME|          0|\n",
      "|PICK_UP_ADDRESS|          0|\n",
      "+---------------+-----------+\n",
      "\n",
      "Initial number of rows: 91712\n",
      "************\n",
      "\n",
      "3: Carmel_B00256.csv\n",
      "[('Date', 'string'), ('Time', 'string'), ('PU_Adress', 'string'), ('Base_No', 'string')]\n",
      "+--------+----+---------------+-------+\n",
      "|    Date|Time|      PU_Adress|Base_No|\n",
      "+--------+----+---------------+-------+\n",
      "|7/1/2014|0:00|260 W 44 St NYC| B00256|\n",
      "|7/1/2014|0:00|125 W 29 St Nyc| B00256|\n",
      "|7/1/2014|0:00|141 W 28 St Nyc| B00256|\n",
      "+--------+----+---------------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|   Column|Nbr of Null|\n",
      "+---------+-----------+\n",
      "|     Date|          0|\n",
      "|     Time|          0|\n",
      "|PU_Adress|          0|\n",
      "|  Base_No|          0|\n",
      "+---------+-----------+\n",
      "\n",
      "Initial number of rows: 256519\n",
      "************\n",
      "\n",
      "4: Dial7_B00887.csv\n",
      "[('Date', 'string'), ('Time', 'string'), ('State', 'string'), ('PuFrom', 'string'), ('Address', 'string'), ('Street', 'string')]\n",
      "+----------+-----+--------------------+---------+-------+--------------------+\n",
      "|      Date| Time|               State|   PuFrom|Address|              Street|\n",
      "+----------+-----+--------------------+---------+-------+--------------------+\n",
      "|2014.07.06|14:30|NY               ...|MANHATTAN|     50|MURRAY ST           |\n",
      "|2014.07.04| 7:15|NY               ...|MANHATTAN|    143|AVENUE B            |\n",
      "|2014.07.05| 5:45|NY               ...|MANHATTAN|    125|CHRISTOPHER ST      |\n",
      "+----------+-----+--------------------+---------+-------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-------+-----------+\n",
      "| Column|Nbr of Null|\n",
      "+-------+-----------+\n",
      "|   Date|          0|\n",
      "|   Time|          0|\n",
      "|  State|          0|\n",
      "| PuFrom|          0|\n",
      "|Address|          0|\n",
      "| Street|          0|\n",
      "+-------+-----------+\n",
      "\n",
      "Initial number of rows: 194992\n",
      "************\n",
      "\n",
      "5: Diplo_B01196.csv\n",
      "[('Date', 'string'), ('Time', 'string'), ('PU_Address', 'string')]\n",
      "+--------+-----------+--------------------+\n",
      "|    Date|       Time|          PU_Address|\n",
      "+--------+-----------+--------------------+\n",
      "|7/1/2014|12:00:00 AM| 2396 Valentine A...|\n",
      "|7/1/2014|12:01:00 AM| 1859 Walton Ave ...|\n",
      "|7/1/2014|12:02:00 AM| 2431 Jerome Ave ...|\n",
      "+--------+-----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 349:============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|    Column|Nbr of Null|\n",
      "+----------+-----------+\n",
      "|      Date|          0|\n",
      "|      Time|          0|\n",
      "|PU_Address|          0|\n",
      "+----------+-----------+\n",
      "\n",
      "Initial number of rows: 98550\n",
      "************\n",
      "\n",
      "6: Federal_02216.csv\n",
      "[('Date', 'string'), ('Time', 'string'), ('PU_Address2', 'string'), ('DO_Address', 'string'), ('Routing_Details', 'string'), ('PU_Address5', 'string'), ('Status', 'string')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:45:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Date, Time, PU_Address, DO_Address, Routing Details, PU_Address, Status\n",
      " Schema: Date, Time, PU_Address2, DO_Address, Routing Details, PU_Address5, Status\n",
      "Expected: PU_Address2 but found: PU_Address\n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/Federal_02216.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|      Date|    Time|         PU_Address2|          DO_Address|     Routing_Details|         PU_Address5|   Status|\n",
      "+----------+--------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|07/01/2014|07:15 AM|Brooklyn Museum, ...|1 Brookdale Plaza...|PU: Brooklyn Muse...|Brooklyn Museum, ...|Cancelled|\n",
      "|07/01/2014|07:30 AM|33 Robert Dr., Sh...|John F Kennedy In...|PU: 33 Robert Dr....|33 Robert Dr., Sh...|  Arrived|\n",
      "|07/01/2014|08:00 AM|60 Glenmore Ave.,...|2171 Nostrand Ave...|PU: 60 Glenmore A...|60 Glenmore Ave.,...| Assigned|\n",
      "+----------+--------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+---------------+-----------+\n",
      "|         Column|Nbr of Null|\n",
      "+---------------+-----------+\n",
      "|           Date|          0|\n",
      "|           Time|          0|\n",
      "|    PU_Address2|          0|\n",
      "|     DO_Address|          0|\n",
      "|Routing_Details|          0|\n",
      "|    PU_Address5|          0|\n",
      "|         Status|          0|\n",
      "+---------------+-----------+\n",
      "\n",
      "Initial number of rows: 276\n",
      "************\n",
      "\n",
      "7: Firstclass_B01536.csv\n",
      "[('DATE', 'string'), ('TIME', 'string'), ('PICK_UP_ADDRESS', 'string')]\n",
      "+--------+-----------+--------------------+\n",
      "|    DATE|       TIME|     PICK_UP_ADDRESS|\n",
      "+--------+-----------+--------------------+\n",
      "|7/1/2014|12:02:00 AM| 5360 Broadway Ki...|\n",
      "|7/1/2014|12:02:00 AM|    546 Isham St NYC|\n",
      "|7/1/2014|12:03:00 AM| 234 Bradhurst Av...|\n",
      "+--------+-----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+\n",
      "|         Column|Nbr of Null|\n",
      "+---------------+-----------+\n",
      "|           DATE|          0|\n",
      "|           TIME|          0|\n",
      "|PICK_UP_ADDRESS|          0|\n",
      "+---------------+-----------+\n",
      "\n",
      "Initial number of rows: 166769\n",
      "************\n",
      "\n",
      "8: Highclass_B01717.csv\n",
      "[('DATE', 'string'), ('TIME', 'string'), ('PU_Address', 'string')]\n",
      "+--------+-----------+--------------------+\n",
      "|    DATE|       TIME|          PU_Address|\n",
      "+--------+-----------+--------------------+\n",
      "|7/1/2014|12:00:00 AM| 2976 Marion Ave ...|\n",
      "|7/1/2014|12:01:00 AM| 780 Grand Concou...|\n",
      "|7/1/2014|12:01:00 AM| 105 Elliot Pl Hi...|\n",
      "+--------+-----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|    Column|Nbr of Null|\n",
      "+----------+-----------+\n",
      "|      DATE|          0|\n",
      "|      TIME|          0|\n",
      "|PU_Address|          0|\n",
      "+----------+-----------+\n",
      "\n",
      "Initial number of rows: 151925\n",
      "************\n",
      "\n",
      "9: Lyft_B02510.csv\n",
      "[('time_of_trip', 'string'), ('start_lat', 'string'), ('start_lng', 'string')]\n",
      "+---------------+---------+---------+\n",
      "|   time_of_trip|start_lat|start_lng|\n",
      "+---------------+---------+---------+\n",
      "|  9/4/2014 9:51| 40.64705|-73.77988|\n",
      "|8/27/2014 21:13| 40.74916|-73.98373|\n",
      "| 9/4/2014 14:16| 40.64065|-73.97594|\n",
      "+---------------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "|      Column|Nbr of Null|\n",
      "+------------+-----------+\n",
      "|time_of_trip|          0|\n",
      "|   start_lat|          0|\n",
      "|   start_lng|          0|\n",
      "+------------+-----------+\n",
      "\n",
      "Initial number of rows: 267700\n",
      "************\n",
      "\n",
      "10: Prestige_B01338.csv\n",
      "[('DATE', 'string'), ('TIME', 'string'), ('PICK_UP_ADDRESS', 'string')]\n",
      "+--------+-----------+--------------------+\n",
      "|    DATE|       TIME|     PICK_UP_ADDRESS|\n",
      "+--------+-----------+--------------------+\n",
      "|7/1/2014|12:00:00 AM| 2557 Marion Ave ...|\n",
      "|7/1/2014|12:00:00 AM| 45 E Mosholu Pkw...|\n",
      "|7/1/2014|12:00:00 AM| 458 E 143rd St M...|\n",
      "+--------+-----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+\n",
      "|         Column|Nbr of Null|\n",
      "+---------------+-----------+\n",
      "|           DATE|          0|\n",
      "|           TIME|          0|\n",
      "|PICK_UP_ADDRESS|          0|\n",
      "+---------------+-----------+\n",
      "\n",
      "Initial number of rows: 320641\n",
      "************\n",
      "\n",
      "11: Skyline_B00111.csv\n",
      "[('Date', 'string'), ('Time', 'string'), ('Street_Address', 'string'), ('City_State', 'string')]\n",
      "+--------+--------------+--------------------+--------------------+\n",
      "|    Date|          Time|      Street_Address|          City_State|\n",
      "+--------+--------------+--------------------+--------------------+\n",
      "|7/1/2014|    20:27     |    622 THIRD AV ...|     M           ...|\n",
      "|7/1/2014|    21:04     |     E 77TH ST   ...|     M           ...|\n",
      "|7/1/2014|    22:20     |    67 WEST PALIS...|    PALISADES PAR...|\n",
      "+--------+--------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------+-----------+\n",
      "|        Column|Nbr of Null|\n",
      "+--------------+-----------+\n",
      "|          Date|          0|\n",
      "|          Time|          0|\n",
      "|Street_Address|          0|\n",
      "|    City_State|          0|\n",
      "+--------------+-----------+\n",
      "\n",
      "Initial number of rows: 127696\n",
      "************\n",
      "\n",
      "12: other-FHV-data-jan-aug-2015.csv\n",
      "[('Base_Number', 'string'), ('Base_Name', 'string'), ('Pick_Up_Date', 'string'), ('Number_of_Trips', 'string'), ('Number_of_Vehicles', 'string')]\n",
      "+-----------+--------------------+------------+---------------+------------------+\n",
      "|Base_Number|           Base_Name|Pick_Up_Date|Number_of_Trips|Number_of_Vehicles|\n",
      "+-----------+--------------------+------------+---------------+------------------+\n",
      "|     B00013|   LOVE CORP CAR INC|  01/01/2015|            26 |               17 |\n",
      "|     B00014| NY ONE CORP CAR INC|  01/01/2015|            45 |               24 |\n",
      "|     B00029|COMMUNITY CAR SVC...|  01/01/2015|           731 |               36 |\n",
      "+-----------+--------------------+------------+---------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+\n",
      "|            Column|Nbr of Null|\n",
      "+------------------+-----------+\n",
      "|       Base_Number|          0|\n",
      "|         Base_Name|          0|\n",
      "|      Pick_Up_Date|          0|\n",
      "|   Number_of_Trips|          0|\n",
      "|Number_of_Vehicles|          0|\n",
      "+------------------+-----------+\n",
      "\n",
      "Initial number of rows: 26181\n",
      "************\n",
      "\n",
      "13: Uber-Jan-Feb-FOIL.csv\n",
      "[('dispatching_base_number', 'string'), ('date', 'string'), ('active_vehicles', 'string'), ('trips', 'string')]\n",
      "+-----------------------+--------+---------------+-----+\n",
      "|dispatching_base_number|    date|active_vehicles|trips|\n",
      "+-----------------------+--------+---------------+-----+\n",
      "|                 B02512|1/1/2015|            190| 1132|\n",
      "|                 B02765|1/1/2015|            225| 1765|\n",
      "|                 B02764|1/1/2015|           3427|29421|\n",
      "+-----------------------+--------+---------------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+-----------+\n",
      "|              Column|Nbr of Null|\n",
      "+--------------------+-----------+\n",
      "|dispatching_base_...|          0|\n",
      "|                date|          0|\n",
      "|     active_vehicles|          0|\n",
      "|               trips|          0|\n",
      "+--------------------+-----------+\n",
      "\n",
      "Initial number of rows: 354\n",
      "************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "all_columns = []\n",
    "for key in df_list.keys():\n",
    "    if 'uber-raw-data' not in key:\n",
    "        print(f'{x}: {key}')\n",
    "        print(df_list[key].dtypes)\n",
    "        df_list[key].show(3)\n",
    "        count_null_values_in_df(df_list[key])\n",
    "        all_columns.append(df_list[key].schema.names)\n",
    "        x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0d406cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A unique list of column names:\n",
      " {'start_lng', 'status', 'date', 'pick_up_address', 'borough', 'locationid', 'number_of_vehicles', 'street_address', 'city_state', 'dispatching_base_number', 'pu_address', 'pick_up_date', 'routing_details', 'zone', 'active_vehicles', 'pu_address5', 'base_name', 'pufrom', 'start_lat', 'do_address', 'base_number', 'number_of_trips', 'trips', 'pu_adress', 'state', 'time', 'street', 'address', 'base_no', 'pu_address2', 'time_of_trip'}\n"
     ]
    }
   ],
   "source": [
    "all_columns = [val for sublist in all_columns for val in sublist]\n",
    "all_columns = [x.strip().lower() for x in all_columns]\n",
    "all_columns = set(all_columns)\n",
    "print(f\"A unique list of column names:\\n {all_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250377a",
   "metadata": {},
   "source": [
    "### Save cleaned files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16769e10",
   "metadata": {},
   "source": [
    "### Preparing a unified file for FHV questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73faef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------------+\n",
      "|DATE|TIME|PICK_UP_ADDRESS|\n",
      "+----+----+---------------+\n",
      "+----+----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_names = df_list['American_B01362.csv'].schema.names\n",
    "mySchema = StructType([StructField(c, StringType()) for c in col_names])\n",
    "FHV_10_companies_data = SparkSession(sc).createDataFrame(data=[], schema=mySchema)\n",
    "FHV_10_companies_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9423148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91712"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.'American_B01362.csv'\n",
    "FHV_10_companies_data = FHV_10_companies_data.union(df_list['American_B01362.csv'])\n",
    "df_list['American_B01362.csv'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fd226a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256519"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 'Carmel_B00256.csv'\n",
    "tmp = df_list['Carmel_B00256.csv'].drop('Base_No')\n",
    "tmp = tmp.withColumnRenamed(\"PU_Adress\", \"PICK_UP_ADDRESS\")\n",
    "df_list['Carmel_B00256.csv'] = tmp\n",
    "FHV_10_companies_data = FHV_10_companies_data.union(tmp)\n",
    "df_list['Carmel_B00256.csv'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e8ffc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194992"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 'Dial7_B00887.csv'\n",
    "columns_to_drop = ['State','PuFrom', 'Address']\n",
    "tmp = df_list['Dial7_B00887.csv'].drop(*columns_to_drop)\n",
    "tmp = tmp.withColumnRenamed(\"Street\", \"PICK_UP_ADDRESS\")\n",
    "df_list['Dial7_B00887.csv'] = tmp\n",
    "FHV_10_companies_data = FHV_10_companies_data.union(tmp)\n",
    "df_list['Dial7_B00887.csv'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e8a1384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98550"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 'Diplo_B01196.csv'\n",
    "tmp = df_list['Diplo_B01196.csv'].withColumnRenamed(\"PU_Address\", \"PICK_UP_ADDRESS\")\n",
    "df_list['Diplo_B01196.csv'] = tmp\n",
    "FHV_10_companies_data = FHV_10_companies_data.union(tmp)\n",
    "df_list['Diplo_B01196.csv'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87338deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. 'Federal_02216.csv'\n",
    "columns_to_drop = ['DO_Address','Routing_Details', 'Status', 'PU_Address2']\n",
    "tmp = df_list['Federal_02216.csv'].drop(*columns_to_drop)\n",
    "tmp = tmp.withColumnRenamed(\"PU_Address5\", \"PICK_UP_ADDRESS\")\n",
    "df_list['Federal_02216.csv'] = tmp\n",
    "FHV_10_companies_data = FHV_10_companies_data.union(tmp)\n",
    "df_list['Federal_02216.csv'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc91763a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166769"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.'Firstclass_B01536.csv'\n",
    "FHV_10_companies_data = FHV_10_companies_data.union(df_list['Firstclass_B01536.csv'])\n",
    "df_list['Firstclass_B01536.csv'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90f57c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151925"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7.'Highclass_B01717.csv'\n",
    "tmp = df_list['Highclass_B01717.csv'].withColumnRenamed(\"PU_Address\", \"PICK_UP_ADDRESS\")\n",
    "df_list['Highclass_B01717.csv'] = tmp\n",
    "FHV_10_companies_data = FHV_10_companies_data.union(tmp)\n",
    "df_list['Highclass_B01717.csv'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c06e8661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+---------+\n",
      "|   time_of_trip|start_lat|start_lng|\n",
      "+---------------+---------+---------+\n",
      "|  9/4/2014 9:51| 40.64705|-73.77988|\n",
      "|8/27/2014 21:13| 40.74916|-73.98373|\n",
      "| 9/4/2014 14:16| 40.64065|-73.97594|\n",
      "+---------------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8.'Lyft_B02510.csv'\n",
    "df_list['Lyft_B02510.csv'].show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "807c7b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127696"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9.'Skyline_B00111.csv'\n",
    "tmp = df_list['Skyline_B00111.csv'].drop('City_State')\n",
    "tmp = tmp.withColumnRenamed(\"Street_Address\", \"PICK_UP_ADDRESS\")\n",
    "df_list['Skyline_B00111.csv'] = tmp\n",
    "FHV_10_companies_data = FHV_10_companies_data.union(tmp)\n",
    "df_list['Skyline_B00111.csv'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c895df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320641"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10.'Prestige_B01338.csv'\n",
    "FHV_10_companies_data = FHV_10_companies_data.union(df_list['Prestige_B01338.csv'])\n",
    "df_list['Prestige_B01338.csv'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2db351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1409080"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FHV_10_companies_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e590d519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxi-zone-lookup.parquet\n",
      "American_B01362.parquet\n",
      "Carmel_B00256.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dial7_B00887.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diplo_B01196.parquet\n",
      "Federal_02216.parquet\n",
      "Firstclass_B01536.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:45:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Date, Time, PU_Address\n",
      " Schema: Date, Time, PU_Address5\n",
      "Expected: PU_Address5 but found: PU_Address\n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/Federal_02216.csv\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highclass_B01717.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 491:============================>                            (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyft_B02510.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prestige_B01338.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skyline_B00111.parquet\n",
      "other-FHV-data-jan-aug-2015.parquet\n",
      "Uber-Jan-Feb-FOIL.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "if server_mode:\n",
    "    path = 'hdfs://192.168.2.74:9000/user/ubuntu/uber-tlc-foil-response/other-FHV-data'\n",
    "else:\n",
    "    path = os.getcwd() + '/DATA/'\n",
    "\n",
    "for key in df_list.keys():\n",
    "    if 'uber-raw-data' not in key:\n",
    "        file = os.path.splitext(key)[0]+\".parquet\"\n",
    "        print(file)\n",
    "        df_list[key].write.mode(\"overwrite\").parquet(path+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70903dd7",
   "metadata": {},
   "source": [
    "## Read the unified \"FHV_10_companies_data\" file in parquet format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f5889e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 12:45:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Date, Time, PU_Address\n",
      " Schema: Date, Time, PU_Address5\n",
      "Expected: PU_Address5 but found: PU_Address\n",
      "CSV file: file:///home/naeim/Dropbox/UU_Master/Fourth%20Semester/Data%20Engineering/Assignments/Project/Code/data_engineering1_project/DATA/Federal_02216.csv\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "if server_mode:\n",
    "    path = 'hdfs://192.168.2.74:9000/user/ubuntu/uber-tlc-foil-response/other-FHV-data'\n",
    "else:\n",
    "    path = os.getcwd() + '/DATA/'\n",
    "\n",
    "FHV_file = path+'FHV_10_companies_data.parquet'\n",
    "FHV_10_companies_data.write.mode(\"overwrite\").parquet(FHV_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4663e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- TIME: string (nullable = true)\n",
      " |-- PICK_UP_ADDRESS: string (nullable = true)\n",
      "\n",
      "+--------+----+---------------+\n",
      "|    DATE|TIME|PICK_UP_ADDRESS|\n",
      "+--------+----+---------------+\n",
      "|7/1/2014|0:00|260 W 44 St NYC|\n",
      "|7/1/2014|0:00|125 W 29 St Nyc|\n",
      "|7/1/2014|0:00|141 W 28 St Nyc|\n",
      "+--------+----+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1409080"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FHV_10_Co = spark_session.read.parquet(FHV_file)\n",
    "FHV_10_Co.printSchema()\n",
    "FHV_10_Co.show(3)\n",
    "FHV_10_Co.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25fcb190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark closed!\n"
     ]
    }
   ],
   "source": [
    "sc.stop()\n",
    "print(\"Spark closed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cae4fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
